---
title: VMware Tanzu Application Service for Kubernetes (TAS4K8s) 0.1.0をKind上にインストールする
tags: ["Cloud Foundry", "Kubernetes", "CF4K8s", "TAS4K8s"]
categories: ["Dev", "PaaS", "CloudFoundry", "CF4K8s", "TAS4K8s"]
---

[VMware Tanzu Application Service for Kubernetes (TAS4K8s)](https://network.pivotal.io/products/tas-for-kubernetes) 0.1.0がリリースされたので試してみます。
今回は[Kind](https://github.com/kubernetes-sigs/kind)をLaptopにインストールし、その上にTASをインストールします。

OSS版は"[cf-for-k8s(CF4K8s) 0.1.0をKind上にインストールする](/entries/519)"を参照してください。内容は一部重複しています。

本記事の内容は基本的に次のドキュメントの通りです。

https://docs.pivotal.io/tas-kubernetes/0-1/


**目次**
<!-- toc -->

### CLIのインストール

* [`kubectl`](https://github.com/kubernetes/kubectl)
* [`kind`](https://github.com/kubernetes-sigs/kind)
* [`kapp`](https://get-kapp.io/) (TAS4k8sのデプロイに使用します)
* [`ytt`](https://get-ytt.io/) (yamlのpatchを適用するために使用します)
* [`bosh`](https://github.com/cloudfoundry/bosh-cli) (yaml内のパスワードとTLS証明書を自動生成するために使用します)
* [`cf`](https://github.com/cloudfoundry/cli)

をインストールします。

```
brew install kubectl
brew install kind
brew install k14s/tap/kapp
brew install k14s/tap/ytt
brew install cloudfoundry/tap/bosh-cli
brew install cloudfoundry/tap/cf-cli
```

動作確認したバージョンは

```
$ kind --version
kind version 0.7.0

$ kubectl version --client=true 
Client Version: version.Info{Major:"1", Minor:"17", GitVersion:"v1.17.3", GitCommit:"06ad960bfd03b39c8310aaf92d1e7c12ce618213", GitTreeState:"clean", BuildDate:"2020-02-13T18:08:14Z", GoVersion:"go1.13.8", Compiler:"gc", Platform:"darwin/amd64"}

$ kapp version
kapp version 0.24.

$ ytt version
ytt version 0.27.1

$ bosh -v      
version 6.2.1-a28042ac-2020-02-10T18:41:00Z

$ cf -v
cf version 6.51.0+2acd15650.2020-04-07
```

です。

### Kubernetesクラスターの作成

TAS4K8sで使用するKubernetesをKindで作成します。Kind用のconfigはOSS版の[`cf-for-k8s/deploy/kind/cluster.yml`](https://github.com/cloudfoundry/cf-for-k8s/blob/v0.1.0/deploy/kind/cluster.yml)に用意されています。

```
wget https://github.com/cloudfoundry/cf-for-k8s/raw/v0.1.0/deploy/kind/cluster.yml
kind create cluster --config=./cluster.yml
```

Kindでは`LoadBalancer` typeの`Service`を作成できないため、hostの`443`ポートをKind内の`31443`ポートに、hostの`80`ポートを`31080`ポートにマッピングするように設定し、
TAS4k8sが`LoadBalancer`の代わりに`NodePort`を使用しても、ホストから`443` or `80`ポートでアクセスできるようにしています。

クラスタが作成されたら`kubectl`で動作確認します。

```
$ kubectl cluster-info
Kubernetes master is running at https://127.0.0.1:32769
KubeDNS is running at https://127.0.0.1:32769/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

$ kubectl get node
NAME                 STATUS   ROLES    AGE   VERSION
kind-control-plane   Ready    master   10m   v1.17.0

$ kubectl get pod -A
NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE
kube-system          coredns-6955765f44-n4qzd                     1/1     Running   0          3m42s
kube-system          coredns-6955765f44-thqj8                     1/1     Running   0          3m42s
kube-system          etcd-kind-control-plane                      1/1     Running   0          3m57s
kube-system          kindnet-s9l7m                                1/1     Running   0          3m42s
kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          3m57s
kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          3m57s
kube-system          kube-proxy-jfbm8                             1/1     Running   0          3m42s
kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          3m57s
local-path-storage   local-path-provisioner-7745554f7f-vnwh9      1/1     Running   0          3m42s
```

KindにはMetrics Serverが含まれておらず、これがないと[`cf push`でエラーが発生する](https://github.com/cloudfoundry/cf-for-k8s/issues/123)ので、Metrics Serverを別途インストールしておきます。

```
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml
```

### VMware Tanzu Application Service for Kubernetesの取得

[Tanzu Network](https://network.pivotal.io) (旧Pivotal Network)にログインして[VMware Tanzu Application Service for Kubernetes](https://network.pivotal.io/products/tas-for-kubernetes)
にアクセスして、`Tanzu Application Service`をクリックしてダウンロードしてください。

![image](https://user-images.githubusercontent.com/106908/79534903-e1dd4780-80b6-11ea-8104-9eacedfe8ed9.png)


`pivnet` CLIがインストール済みであれば、次のコマンドでもダウンロード可能です。

```
pivnet download-product-files --product-slug='tas-for-kubernetes' --release-version='0.1.0' --product-file-id=660279
```

### VMware Tanzu Application Service for Kubernetesの設定ファイルの準備

https://docs.pivotal.io/tas-kubernetes/0-1/installing-tas-for-kubernetes.html

ダウンロードした`tanzu-application-service.0.1.0-build.252.tar`を`tanzu-application-service`ディレクトリに展開します。

```
mkdir -p tanzu-application-service
tar -C tanzu-application-service -xzvf tanzu-application-service.0.1.0-build.252.tar
```

`./bin/generate-values.sh`スクリプトを使って、インストールに必要な設定を生成します。設定項目は`configuration-values`ディレクトリに保存します。

ドキュメントに合わせて、TASのドメインには`*.sys.local.maki.lol`を使用します。

> `*.local.maki.lol`及び`*.apps.local.maki.lol`、`*.sys.local.maki.lol`はAレコードで`127.0.0.1`を返すように登録s亭あります。誰でも利用可能です。

```
mkdir -p configuration-values
cd tanzu-application-service
./bin/generate-values.sh -d "sys.local.maki.lol" > ../configuration-values/deployment-values.yml
```

TAS4K8sで使われるSystemコンポーネントのDockerイメージはDockerHubではなく、[Tanzu Network Container Registry](https://registry.pivotal.io)から取得します。
このアカウント情報を`configuration-values/system-registry-values.yml`に定義します。

```
export TANZU_NETWORK_USERNAME=****************
export TANZU_NETWORK_PASSWORD=****************

cat <<EOF > ../configuration-values/system-registry-values.yml
#@data/values
---
system_registry:
  hostname: registry.pivotal.io
  username: ${TANZU_NETWORK_USERNAME}
  password: ${TANZU_NETWORK_PASSWORD}
EOF
```


### アプリケーションのコンテナイメージを保存するDocker Registryの設定

https://docs.pivotal.io/tas-kubernetes/0-1/configuring-app-image-registry.html

SystemコンポーネントのDockerイメージはTanzu Network Container Registryから取得しましたが、
アプリケーションのDockerイメージはDockerhub, Google Container Registry, VMware Harbor Registryがサポートされています。

ここではDockerhubを使用します。

```
export DOCKERHUB_USERNAME=making
export DOCKERHUB_PASSWORD=********************

cat <<EOF > ../configuration-values/app-registry-values.yml
#@data/values
---
app_registry:
  hostname: https://index.docker.io/v1/
  repository: ${DOCKERHUB_USERNAME}
  username: ${DOCKERHUB_USERNAME}
  password: ${DOCKERHUB_PASSWORD}
EOF
```

### VMware Tanzu Application Service for KubernetesをKindで動かすための設定

OSSの[cf-for-k8](https://github.com/cloudfoundry/cf-for-k8s)から、TAS4K8sをKindで動かすためのoverlay filesを取得します。
これを`custom-overlays`ディレクトリに保存します。

>　⚠️ この方法はTAS4K8sでは保証されていません!!

* [`cf-for-k8s/config-optional/remove-resource-requirements.yml`](https://github.com/cloudfoundry/cf-for-k8s/blob/v0.1.0/config-optional/remove-resource-requirements.yml) ... Kindでもデプロイできるようにリソース(CPU、メモリ)の下限の制約を除外する
* [`cf-for-k8s/config-optional/use-nodeport-for-ingress.yml`](https://github.com/cloudfoundry/cf-for-k8s/blob/v0.1.0/config-optional/use-nodeport-for-ingress.yml) ... IstionのIngress Gatewayに`NodePort`を使用する


```
wget https://github.com/cloudfoundry/cf-for-k8s/raw/v0.1.0/config-optional/use-nodeport-for-ingress.yml -O custom-overlays/use-nodeport-for-ingress.yml
wget https://github.com/cloudfoundry/cf-for-k8s/raw/v0.1.0/config-optional/remove-resource-requirements.yml -O custom-overlays/remove-resource-requirements.yml
```

###  VMware Tanzu Application Service for Kubernetesのインストール

https://docs.pivotal.io/tas-kubernetes/0-1/installing-tas-for-kubernetes.html

`bin/install-tas.sh`スクリプトを使ってインストールを行います。

```
./bin/install-tas.sh ../configuration-values
```

次のようなログが出力されて、インストールが完了します。
初回はDockerイメージのダウンロードと、`kapp`によるデプロイが行われます。

```
$ ./bin/install-tas.sh ../configuration-values

Target cluster 'https://127.0.0.1:32769' (nodes: kind-control-plane)
resolve | final: cfidentity/uaa@sha256:016363eba9544ada12c16ac1e66a7e02241b1ec8074d61f5fa8fd6d7edee3d69 -> registry.pivotal.io/tas-for-kubernetes/uaa-annotated@sha256:b2d8c01426f451fa39bc302e3516bf4b5ab2652874f949be4ced26aa451adab7
resolve | final: cloudfoundry/capi-kpack-watcher:956150dae0a95dcdf3c1f29c23c3bf11db90f7a0@sha256:67125e0d3a4026a23342d80e09aad9284c08ab4f7b3d9a993ae66e403d5d0796 -> registry.pivotal.io/tas-for-kubernetes/capi-kpack-watcher-annotated@sha256:8958b568978de3f093571439d93fb4895ccdd281123b79f4eba56c6be121eadf
resolve | final: cloudfoundry/capi:nginx@sha256:51e4e48c457d5cb922cf0f569e145054e557e214afa78fb2b312a39bb2f938b6 -> registry.pivotal.io/tas-for-kubernetes/capi-annotated@sha256:7560ed0a1175f8a93dcb2ee0a26dbe7127fb0410b801b62861491a0f96b07255
resolve | final: cloudfoundry/cloud-controller-ng:33f461df533c7174241b00759bb7622ea37c58c7@sha256:0bc1b2b3e0c2fcfbd76d7c4a311b728a240b928fcd8d2b2b1e057de88a0adacf -> registry.pivotal.io/tas-for-kubernetes/cloud-controller-ng-annotated@sha256:62f9f3e974ceba981a92b3e508c11e233e4a149a5e76be53c18f63e7a591e61d
resolve | final: cloudfoundry/cnb:0.0.55-bionic -> registry.pivotal.io/tas-for-kubernetes/cnb-annotated@sha256:1d5d893cf2444efeb5d16a471a0fd8cda088a63736c5bceb477a9c342b51b955
resolve | final: dev.registry.pivotal.io/tas-for-kubernetes/pod-webhook@sha256:6120f15c80ceef2bc66602f79acefb5766f9ab602d9146dd04d9eb3569256a12 -> registry.pivotal.io/tas-for-kubernetes/pod-webhook-annotated@sha256:4fde3257d4a42557a4184abdbf9ffe3a44e89c0b305df0ac5da13890be632cd7
resolve | final: dev.registry.pivotal.io/tas-for-kubernetes/setup-ca-certs@sha256:cfe932fcf7ed158b31a9ddca5241e56a295fa7b88cddc3c8c376b58393c524b6 -> registry.pivotal.io/tas-for-kubernetes/setup-ca-certs-annotated@sha256:df984ea209ad8ddedd13a1f37793a0f8f728ab0cca5479ecd60801ba915e6ab5
resolve | final: docker.io/bitnami/postgresql:11.7.0-debian-10-r26 -> registry.pivotal.io/tas-for-kubernetes/postgres-bionic-annotated@sha256:e7dd977c4de19a3848c16843f7cd724ad44141433c2460fc1297bab8b70e414c
resolve | final: docker.io/istio/citadel:1.4.5 -> registry.pivotal.io/tas-for-kubernetes/citadel-annotated@sha256:b8e5503716365ce3919508d72c4555e6581731c2cd56a5d3e123547c276bf541
resolve | final: docker.io/istio/galley:1.4.5 -> registry.pivotal.io/tas-for-kubernetes/galley-annotated@sha256:bd723793a3ae89f1b04c639a2a60717355e509a5a4734b9fcecc75b6ede558be
resolve | final: docker.io/istio/mixer:1.4.5 -> registry.pivotal.io/tas-for-kubernetes/mixer-annotated@sha256:b9472ceaa66dcc34e3ca49813c994ddde6af49ab86bc07ca981ba1f3763d2e00
resolve | final: docker.io/istio/node-agent-k8s:1.4.5 -> registry.pivotal.io/tas-for-kubernetes/node-agent-k8s-annotated@sha256:6519f82af6e85210d0ab81c6b88ae7632073fd98d203e1e073eb0db675fcc45a
resolve | final: docker.io/istio/pilot:1.4.5 -> registry.pivotal.io/tas-for-kubernetes/pilot-annotated@sha256:5fc0e678e471be946719f9a866ac99252d3c7a7d1561020ed34adfba4c457e58
resolve | final: docker.io/istio/proxyv2:1.4.5 -> registry.pivotal.io/tas-for-kubernetes/proxyv2-annotated@sha256:d7792fed2b3e7ffc84bfc50f693a9dd8960883ea9685b12ae1f1ef7ee2133ea3
resolve | final: docker.io/istio/sidecar_injector:1.4.5 -> registry.pivotal.io/tas-for-kubernetes/sidecar_injector-annotated@sha256:81e94732e7301ea9bc568adc391b68c0a1efbdd6f4ac28540d023daa2140d0e5
resolve | final: eirini/opi@sha256:2e0b84c5fcb1e6e5cdb07a70210f2e462aa52119f7a330660a7444a938deefbb -> registry.pivotal.io/tas-for-kubernetes/opi-annotated@sha256:e11165c8070ca70be3dbbfdcf5763e7cbfe679c1c82724b5697a4400fed03cfb
resolve | final: gcr.io/cf-build-service-public/kpack/build-init@sha256:b90a4d2c027ac6cf6b2904383211084d33d6faf9fed38a3d55a09b54e6f671bf -> registry.pivotal.io/tas-for-kubernetes/build-init-annotated@sha256:b90a4d2c027ac6cf6b2904383211084d33d6faf9fed38a3d55a09b54e6f671bf
resolve | final: gcr.io/cf-build-service-public/kpack/completion@sha256:e9cfca6b13c9a5beb70b92634c960cf3c9d8559b4b76f6b94366531705a95b96 -> registry.pivotal.io/tas-for-kubernetes/completion-annotated@sha256:e9cfca6b13c9a5beb70b92634c960cf3c9d8559b4b76f6b94366531705a95b96
resolve | final: gcr.io/cf-build-service-public/kpack/controller@sha256:1d7d80257e2019a474417ba0c7dcfff5612aeec55e24d91ef7b2e4bd0a521a40 -> registry.pivotal.io/tas-for-kubernetes/controller-annotated@sha256:1d7d80257e2019a474417ba0c7dcfff5612aeec55e24d91ef7b2e4bd0a521a40
resolve | final: gcr.io/cf-build-service-public/kpack/lifecycle@sha256:66f723ef7452af4c5d9dd8eec3ade77adcab27df677768acb3c825165f274c87 -> registry.pivotal.io/tas-for-kubernetes/lifecycle-annotated@sha256:66f723ef7452af4c5d9dd8eec3ade77adcab27df677768acb3c825165f274c87
resolve | final: gcr.io/cf-build-service-public/kpack/rebase@sha256:925940d4802c183d0af69a99cfbf48bea5b27e4d9dc4bf363bf71bb34e8a318e -> registry.pivotal.io/tas-for-kubernetes/rebase-annotated@sha256:925940d4802c183d0af69a99cfbf48bea5b27e4d9dc4bf363bf71bb34e8a318e
resolve | final: gcr.io/cf-build-service-public/kpack/webhook@sha256:c2461ef9634c771f2a06bc0371040b43c9a78dd0e4ac1c9fde3f4525e0ae21f2 -> registry.pivotal.io/tas-for-kubernetes/webhook-annotated@sha256:c2461ef9634c771f2a06bc0371040b43c9a78dd0e4ac1c9fde3f4525e0ae21f2
resolve | final: gcr.io/cf-networking-images/cf-k8s-networking/cfroutesync@sha256:758abd1b6144596cef74ad4805bc7e1a6055142cab5719f0d42d0321a14a190d -> registry.pivotal.io/tas-for-kubernetes/cfroutesync-annotated@sha256:07dd28bbbb181298cf1e74e2a46206a9ac1778506a22c34898eb1cd6442e8f92
resolve | final: logcache/cf-k8s-logging@sha256:44e20fa761fb67436eabd70a226d88ca7398619aaa2b3b468405017c75fd9607 -> registry.pivotal.io/tas-for-kubernetes/cf-k8s-logging-annotated@sha256:d50244b42ad1badd5d5874bca1a304e936703c7ec8546e7facd44688df2539b8
resolve | final: logcache/log-cache-cf-auth-proxy@sha256:2fa3c3fc7a4d8ed006502aa239ca95a936ec69eb850de5790b057adcc26cb433 -> registry.pivotal.io/tas-for-kubernetes/log-cache-cf-auth-proxy-annotated@sha256:38c21741e93c66333840bdb3ccc3a4bcdec1d6fd980dc62d6eab8dbc5183eb8d
resolve | final: logcache/log-cache-gateway@sha256:845998ef9769d78b43555eb18757b5f24571fefbe4a267c0ffa7e69071b38177 -> registry.pivotal.io/tas-for-kubernetes/log-cache-gateway-annotated@sha256:951001b19623415ff53f8e768447a33dc78acca29376592c2fdd7b18ada77cd7
resolve | final: logcache/log-cache@sha256:1074a8a64f56d1967758cf9cbd3d388b2e5bd295768231ebbaa9ae8febb7e90a -> registry.pivotal.io/tas-for-kubernetes/log-cache-annotated@sha256:278820d2f9495cd6d81b3b18f4986aff05c6c91b57eac59f69c944d843bc8bc8
resolve | final: logcache/syslog-server@sha256:7a6c85226bb0f92e870c1bbe6555261c9946cdcd8fed2aeac854b7ea0b369a99 -> registry.pivotal.io/tas-for-kubernetes/syslog-server-annotated@sha256:dd9e60fcdc6fa2cd5270427c386e05358919af42988ff2ebda19c0114eb97d1e
resolve | final: metacontroller/metacontroller:v0.4.0 -> registry.pivotal.io/tas-for-kubernetes/metacontroller-tiny-annotated@sha256:731da6e0c4d544e0529126d74b32ccbf7d334db96d60745163d72b1334d93fe3
resolve | final: minio/minio:RELEASE.2020-01-16T22-40-29Z -> registry.pivotal.io/tas-for-kubernetes/minio-bionic-annotated@sha256:106fea82bf6b97d27b73d924e1e4be2308b2e2895779ac0439dde5e57e3a7659

Changes

Namespace             Name                                                            Kind                          Conds.  Age  Op      Wait to    Rs  Ri  
(cluster)             adapters.config.istio.io                                        CustomResourceDefinition      -       -    create  reconcile  -   -  
^                     aggregate-metacontroller-edit                                   ClusterRole                   -       -    create  reconcile  -   -  
...(略)...^                     metacontroller                                                  StatefulSet                   -       -    create  reconcile  -   -  
^                     system-registry-credentials                                     Secret                        -       -    create  reconcile  -   -  

Op:      261 create, 0 delete, 0 update, 0 noop
Wait to: 261 reconcile, 0 delete, 0 noop

1:17:03PM: ---- applying 36 changes [0/261 done] ----
1:17:03PM: create customresourcedefinition/builds.build.pivotal.io (apiextensions.k8s.io/v1beta1) cluster
...(略)...
:23:29PM: ok: reconcile deployment/capi-api-server (apps/v1) namespace: cf-system
1:23:29PM: ---- applying complete [261/261 done] ----
1:23:29PM: ---- waiting complete [261/261 done] ----

Succeeded
```

インストール後の`Pod`一覧は次の通りです。

```
$ kubectl get pod -A 
NAMESPACE              NAME                                                           READY   STATUS      RESTARTS   AGE
build-service          webhook-server-764b96c79c-f22pr                                1/1     Running     0          153m
cf-blobstore           cf-blobstore-minio-58f7b7c998-46mdp                            2/2     Running     0          150m
cf-db                  cf-db-postgresql-0                                             2/2     Running     1          151m
cf-system              capi-api-server-ddd94d8d-dv72c                                 4/4     Running     2          151m
cf-system              capi-api-server-ddd94d8d-fzq45                                 4/4     Running     2          151m
cf-system              capi-clock-5cbb674bc5-fjgbr                                    2/2     Running     1          151m
cf-system              capi-deployment-updater-748ff65d9b-rbfhw                       2/2     Running     1          151m
cf-system              capi-kpack-watcher-7dd5fc9475-wr2lh                            2/2     Running     0          151m
cf-system              capi-worker-7d5c7dcc56-tkzpz                                   2/2     Running     1          151m
cf-system              cfroutesync-55cc67bc6c-cm897                                   2/2     Running     0          150m
cf-system              eirini-c547dbb6b-9ct4t                                         2/2     Running     0          150m
cf-system              fluentd-9kzdh                                                  2/2     Running     1          151m
cf-system              log-cache-668d9495bd-nk986                                     5/5     Running     1          150m
cf-system              uaa-9d74bbb5f-dl5bf                                            2/2     Running     0          150m
istio-system           istio-citadel-767c6db997-gsdzs                                 1/1     Running     0          154m
istio-system           istio-galley-79d6d8969b-csfkf                                  2/2     Running     0          154m
istio-system           istio-ingressgateway-52vg5                                     2/2     Running     0          153m
istio-system           istio-pilot-5cfbf97bc6-tv8b4                                   2/2     Running     0          154m
istio-system           istio-policy-7bf94cc66b-xqj4c                                  2/2     Running     1          153m
istio-system           istio-sidecar-injector-655cf5584-vw7dq                         1/1     Running     0          154m
istio-system           istio-telemetry-6455f48c84-r6xxk                               2/2     Running     0          153m
kpack                  kpack-controller-5dd6fccf96-5r489                              1/1     Running     0          153m
kpack                  kpack-webhook-749cd895d7-sr9zn                                 1/1     Running     0          154m
kube-system            coredns-6955765f44-tzbtj                                       1/1     Running     0          16h
kube-system            coredns-6955765f44-vjl5c                                       1/1     Running     0          16h
kube-system            etcd-kind-control-plane                                        1/1     Running     0          16h
kube-system            kindnet-h62c4                                                  1/1     Running     0          16h
kube-system            kube-apiserver-kind-control-plane                              1/1     Running     0          16h
kube-system            kube-controller-manager-kind-control-plane                     1/1     Running     0          16h
kube-system            kube-proxy-h48d5                                               1/1     Running     0          16h
kube-system            kube-scheduler-kind-control-plane                              1/1     Running     0          16h
kube-system            metrics-server-58c885686f-fb25q                                1/1     Running     0          16h
local-path-storage     local-path-provisioner-7745554f7f-x8dqt                        1/1     Running     0          16h
metacontroller         metacontroller-0                                               2/2     Running     0          151m
```

> `build-service` namespaceはOSSのcf-for-k8sには存在しないです。

インストール後の`Service`一覧は次の通りです。`istio-ingressgateway`が`NodePort`になっており、`31080`->`80`、`31443`->`443`になっていることに注目してください。
Kindの設定内容と一致します。

```
$ kubectl get svc -A
NAMESPACE      NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                                                                      AGE
cf-blobstore   cf-blobstore-minio          ClusterIP   10.96.78.163    <none>        9000/TCP                                                                                                                     6m34s
cf-db          cf-db-postgresql            ClusterIP   10.96.218.112   <none>        5432/TCP                                                                                                                     6m32s
cf-db          cf-db-postgresql-headless   ClusterIP   None            <none>        5432/TCP                                                                                                                     6m32s
cf-system      capi                        ClusterIP   10.96.131.69    <none>        80/TCP                                                                                                                       6m34s
cf-system      cfroutesync                 ClusterIP   10.96.8.232     <none>        80/TCP                                                                                                                       6m34s
cf-system      eirini                      ClusterIP   10.96.99.214    <none>        8085/TCP                                                                                                                     6m34s
cf-system      log-cache                   ClusterIP   10.96.95.99     <none>        8083/TCP                                                                                                                     6m34s
cf-system      log-cache-syslog            ClusterIP   10.96.207.232   <none>        8082/TCP                                                                                                                     6m34s
cf-system      metric-proxy                ClusterIP   10.96.76.205    <none>        8080/TCP                                                                                                                     6m34s
cf-system      uaa                         ClusterIP   10.96.43.61     <none>        8080/TCP                                                                                                                     6m32s
default        kubernetes                  ClusterIP   10.96.0.1       <none>        443/TCP                                                                                                                      29m
istio-system   istio-citadel               ClusterIP   10.96.221.120   <none>        8060/TCP,15014/TCP                                                                                                           6m34s
istio-system   istio-galley                ClusterIP   10.96.55.132    <none>        443/TCP,15014/TCP,9901/TCP,15019/TCP                                                                                         6m34s
istio-system   istio-ingressgateway        NodePort    10.96.33.9      <none>        15020:32508/TCP,80:31080/TCP,443:31443/TCP,15029:32477/TCP,15030:30356/TCP,15031:30882/TCP,15032:31281/TCP,15443:30490/TCP   6m33s
istio-system   istio-pilot                 ClusterIP   10.96.100.89    <none>        15010/TCP,15011/TCP,8080/TCP,15014/TCP                                                                                       6m33s
istio-system   istio-policy                ClusterIP   10.96.107.158   <none>        9091/TCP,15004/TCP,15014/TCP                                                                                                 6m33s
istio-system   istio-sidecar-injector      ClusterIP   10.96.157.123   <none>        443/TCP                                                                                                                      6m33s
istio-system   istio-telemetry             ClusterIP   10.96.3.64      <none>        9091/TCP,15004/TCP,15014/TCP,42422/TCP                                                                                       6m32s
kpack          kpack-webhook               ClusterIP   10.96.104.123   <none>        443/TCP                                                                                                                      6m34s
kube-system    kube-dns                    ClusterIP   10.96.0.10      <none>        53/UDP,53/TCP,9153/TCP   
kube-system    metrics-server              ClusterIP   10.96.161.224   <none>        443/TCP                                                                                                                      3m34s
```

インストール後の`PersistentVolume`一覧は次の通りです。データベースとしてPostgreSQL、BlobstoreとしてMinioが`PersistentVolume`を使用しています。


```
$ kubectl get pv    
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                             STORAGECLASS   REASON   AGE
pvc-7c5b8a6d-8341-4e2b-ae37-f90c129c9e93   10Gi       RWO            Delete           Bound    cf-blobstore/cf-blobstore-minio   standard                155m
pvc-ce33e0bf-97c1-456f-bead-1858c2c5048d   8Gi        RWO            Delete           Bound    cf-db/data-cf-db-postgresql-0     standard                155m
```

`kapp`を使ってインストールした場合は`kapp inspect -a <アプリ名> --tree`コマンドで、作成されたリソース一覧を確認できます。

次のエンドポイントにアクセスして、Cloud Controllerのバージョンを確認できます。

```
$ curl -s -k https://api.sys.local.maki.lol/v2/info | jq .
{
  "name": "",
  "build": "",
  "support": "",
  "version": 0,
  "description": "",
  "authorization_endpoint": "https://login.sys.local.maki.lol",
  "token_endpoint": "https://uaa.sys.local.maki.lol",
  "min_cli_version": "",
  "min_recommended_cli_version": "",
  "app_ssh_endpoint": "TODO.TODO",
  "app_ssh_host_key_fingerprint": "placeholder",
  "app_ssh_oauth_client": "placeholder",
  "doppler_logging_endpoint": "wss://doppler.sys.local.maki.lol:443",
  "api_version": "2.148.0",
  "osbapi_version": "2.15",
  "routing_endpoint": "https://api.sys.local.maki.lol/routing"
}
```

### VMware Tanzu Application Service for Kubernetesにログイン

https://docs.pivotal.io/tas-kubernetes/0-1/installing-tas-for-kubernetes.html#post-installation-system-configuration

早速VMware Tanzu Application Service for Kubernetesにログインしてみます。

`admin`ユーザーのパスワードは`bosh int ../configuration-values/deployment-values.yml`で取得できます。


次のコマンドでログインします。

```
cf login -a api.sys.local.maki.lol -u admin -p $(bosh int ../configuration-values/deployment-values.yml --path /cf_admin_password) --skip-ssl-validation
```

次のようなログが出力されればOKです。

```
API endpoint: api.sys.local.maki.lol

Authenticating...
OK

Targeted org system




API endpoint:   https://api.sys.local.maki.lol (API version: 3.83.0)
User:           admin
Org:            system
Space:          No space targeted, use 'cf target -s SPACE'
```

Docker Imageをそのままデプロイできる機能を有効にします。0.1.0ではBuildpackを使う場合はもこの設定が必要です。

```
$ cf enable-feature-flag diego_docker
Setting status of diego_docker as admin...

OK

Feature diego_docker Enabled.
```

UAAにアクセスしてみます。URLは https://uaa.sys.local.maki.lol です。

![image](https://user-images.githubusercontent.com/106908/79457457-36d37c00-802b-11ea-9e6c-c1000a91a9d8.png)


### Org、Spaceの作成

`demo` Orgと`demo` Spaceを作成します。

```
cf create-org demo
cf create-space demo -o demo
cf target -o demo -s demo
```

### Javaアプリケーションのデプロイ

Spring Bootのアプリをデプロイします。


雛形プロジェクトを作成し、ビルドします。

```
cd /tmp
curl https://start.spring.io/starter.tgz \
       -d artifactId=hello-cf \
       -d baseDir=hello-cf \
       -d dependencies=web,actuator \
       -d packageName=com.example \
       -d applicationName=HelloCfApplication | tar -xzvf -
cd hello-cf
./mvnw clean package -DskipTests=true
```


`cf push`します。

```
$ cf push hello -p target/hello-cf-0.0.1-SNAPSHOT.jar
Pushing app hello to org demo / space demo as admin...
Getting app info...
Creating app with these attributes...
+ name:       hello
  path:       /private/tmp/hello-cf/target/hello-cf-0.0.1-SNAPSHOT.jar
  routes:
+   hello.sys.local.maki.lol

Creating app hello...
Mapping routes...
Comparing local files to remote cache...
Packaging files to upload...
Uploading files...
 315.39 KiB / 315.39 KiB [===========================================================================================================================================================] 100.00% 1s

Waiting for API to complete processing files...

Staging app and tracing logs...

Waiting for app to start...

name:                hello
requested state:     started
isolation segment:   placeholder
routes:              hello.sys.local.maki.lol
last uploaded:       Fri 17 Apr 14:21:22 JST 2020
stack:               
buildpacks:          

type:           web
instances:      1/1
memory usage:   1024M
     state     since                  cpu    memory    disk      details
#0   running   2020-04-17T05:21:47Z   0.0%   0 of 1G   0 of 1G  
```

デプロイが成功しました。

`cf apps`コマンドでアプリケーション一覧を確認します。

```
$ cf apps
Getting apps in org demo / space demo as admin...
OK

name    requested state   instances   memory   disk   urls
hello   started           1/1         1G       1G     hello.sys.local.maki.lol
```


`cf app`コマンドでアプリの詳細を確認できます。

```
$ cf app hello
Showing health and status for app hello in org demo / space demo as admin...

name:                hello
requested state:     started
isolation segment:   placeholder
routes:              hello.sys.local.maki.lol
last uploaded:       Fri 17 Apr 14:21:22 JST 2020
stack:               
buildpacks:          

type:           web
instances:      1/1
memory usage:   1024M
     state     since                  cpu    memory    disk      details
#0   running   2020-04-17T05:21:47Z   0.0%   0 of 1G   0 of 1G   
```

`/actuator/health`エンドポイントにアクセスします。

```
$ curl http://hello.sys.local.maki.lol/actuator/health
{"status":"UP"}
```

0.1.0ではHTTPエンドポイントだけ利用可能で、HTTPSやTCPは使えません。

また、これまでのCloud FoundryではBuildpack v2が使用されていましたが、cf-for-k8sでは[kpack](https://github.com/pivotal/kpack)経由で[Cloud Native Buildpacks](https://buildpacks.io/)が使用されます。

`cf push`で作成されたコンテナイメージはインストール時に設定したDocker Registryにデプロイされます。実際にDockerHubにイメージがデプロイされていました。

![image](https://user-images.githubusercontent.com/106908/79461235-d9422e00-8030-11ea-945d-fbbeddbb7a54.png)


なお、Kpackが使用するCloud Native Buildpacks一覧は`kubectl get builder -n cf-workloads-staging  cf-autodetect-builder -o yaml`で確認っできます。
現時点では言語として、Java, Node.js, .NET, Goが利用できます。(Builderとして`cloudfoundry/cnb:0.0.55-bionic`が登録されています。)

`cf logs hello --recent`コマンドでログを確認できます。Cloud Native Buildpacksの実行結果が出力されています。

cf-for-k8sでは、EiriniというコンポーネントがCloud Controllerからのリクエストを受けてKubernetesにアプリを`Statefulset`としてデプロイします。Eiriniが作成した`StatefulSet`及び、それにより作られた`Pod`は次のコマンドで確認できます。

```
$ kubectl get statefulset,pod -n cf-workloads
NAME                                     READY   AGE
statefulset.apps/hello-demo-6fd34f17db   1/1     107m

NAME                          READY   STATUS    RESTARTS   AGE
pod/hello-demo-6fd34f17db-0   2/2     Running   0          107m
```

> 現時点でTAS4K8sでDeveloper(`cf push`を使うユーザー)が`kubectl`を使うことは想定していません。`kubectl`はPlatformエンジニアが使う想定です。

### Smoke Testの実行

`cf push`は成功しましたが、インストールが適切にできているか確認するために、Smoke Testを実行してみます。
Smoke Testを実行するには[ginkgo](https://github.com/onsi/ginkgo)をインストールする必要があります。

```
brew install go
go get -u github.com/onsi/ginkgo/ginkgo
export PATH=$PATH:$HOME/go/bin
```

次のコマンドでSmoke Testを実行します。

```
export SMOKE_TEST_APPS_DOMAIN=sys.local.maki.lol
export SMOKE_TEST_API_ENDPOINT=api.sys.local.maki.lol
export SMOKE_TEST_USERNAME=admin
export SMOKE_TEST_PASSWORD=$(bosh int ../configuration-values/deployment-values.yml --path /cf_admin_password)
export SMOKE_TEST_SKIP_SSL=true
./config/cf-for-k8s/hack/run-smoke-tests.sh
```
次のような結果が出力されれば成功です。

```
Running Suite: Smoke Tests Suite
================================
Random Seed: 1587107442
Will run 2 of 2 specs

..(略)..

Ran 2 of 2 Specs in 119.501 seconds
SUCCESS! -- 2 Passed | 0 Failed | 0 Pending | 0 Skipped
PASS

Ginkgo ran 1 suite in 2m0.870246904s
Test Suite Passed
```

---

TAS4K8s 0.1.0を試しました。


まだまだ制限は多く、Productionで利用できるレベルではないですが、少しずつ機能が追加されていくでしょう。
現時点でのKnown Issuesは次のページに記載されています。

https://docs.pivotal.io/tas-kubernetes/0-1/release-notes.html#known-issues


